{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from run_BERT_classifier import preprocessing_for_bert\n",
    "from run_BERT_classifier import get_input_data\n",
    "from run_BERT_classifier import BertClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "dummy_inputs = preprocessing_for_bert([\"bla asdf\"])  #tokens und attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define labels and encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "news_classes = ['entertainment', 'politics', 'tech', 'sport', 'business']\n",
    "num_labels_news = len(news_classes)\n",
    "le_news = LabelEncoder()\n",
    "le_news.fit(news_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_model = BertClassifier(num_labels=num_labels_news)\n",
    "news_model.load_state_dict(torch.load(\"models/BERT_classifier_news_data.pt\", map_location=device))# load finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to onnx:\n",
    "torch.onnx.export(news_model, \n",
    "                  dummy_inputs, \n",
    "                  \"news_model.onnx\",\n",
    "                  export_params=True, # store the trained parameter weights inside the model file\n",
    "                  input_names = ['input_ids', 'input_masks'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input_ids[INT64, 1x512]\n",
      "  %input_masks[INT64, 1x512]\n",
      ") initializers (\n",
      "  %bert.embeddings.word_embeddings.weight[FLOAT, 30522x768]\n",
      "  %bert.embeddings.position_embeddings.weight[FLOAT, 512x768]\n",
      "  %bert.embeddings.token_type_embeddings.weight[FLOAT, 2x768]\n",
      "  %bert.embeddings.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.embeddings.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.0.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.0.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.1.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.1.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.2.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.2.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.3.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.3.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.4.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.4.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.5.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.5.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.6.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.6.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.7.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.7.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.8.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.8.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.9.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.9.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.10.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.10.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.self.query.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.self.key.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.self.value.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.attention.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\n",
      "  %bert.encoder.layer.11.output.dense.bias[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.output.LayerNorm.weight[FLOAT, 768]\n",
      "  %bert.encoder.layer.11.output.LayerNorm.bias[FLOAT, 768]\n",
      "  %classifier.0.weight[FLOAT, 50x768]\n",
      "  %classifier.0.bias[FLOAT, 50]\n",
      "  %classifier.2.weight[FLOAT, 5x50]\n",
      "  %classifier.2.bias[FLOAT, 5]\n",
      "  %onnx::Equal_1429[INT64, 2]\n",
      "  %onnx::ConstantOfShape_1430[INT64, 1]\n",
      "  %onnx::Gather_1431[INT64, 1x512]\n",
      "  %onnx::MatMul_1432[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1433[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1438[INT64, 4]\n",
      "  %onnx::MatMul_1439[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1444[INT64, 4]\n",
      "  %onnx::Reshape_1449[INT64, 4]\n",
      "  %onnx::Reshape_1453[INT64, 3]\n",
      "  %onnx::MatMul_1454[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1455[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1456[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1457[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1458[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1463[INT64, 4]\n",
      "  %onnx::MatMul_1464[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1469[INT64, 4]\n",
      "  %onnx::Reshape_1474[INT64, 4]\n",
      "  %onnx::Reshape_1478[INT64, 3]\n",
      "  %onnx::MatMul_1479[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1480[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1481[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1482[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1483[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1488[INT64, 4]\n",
      "  %onnx::MatMul_1489[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1494[INT64, 4]\n",
      "  %onnx::Reshape_1499[INT64, 4]\n",
      "  %onnx::Reshape_1503[INT64, 3]\n",
      "  %onnx::MatMul_1504[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1505[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1506[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1507[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1508[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1513[INT64, 4]\n",
      "  %onnx::MatMul_1514[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1519[INT64, 4]\n",
      "  %onnx::Reshape_1524[INT64, 4]\n",
      "  %onnx::Reshape_1528[INT64, 3]\n",
      "  %onnx::MatMul_1529[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1530[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1531[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1532[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1533[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1538[INT64, 4]\n",
      "  %onnx::MatMul_1539[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1544[INT64, 4]\n",
      "  %onnx::Reshape_1549[INT64, 4]\n",
      "  %onnx::Reshape_1553[INT64, 3]\n",
      "  %onnx::MatMul_1554[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1555[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1556[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1557[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1558[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1563[INT64, 4]\n",
      "  %onnx::MatMul_1564[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1569[INT64, 4]\n",
      "  %onnx::Reshape_1574[INT64, 4]\n",
      "  %onnx::Reshape_1578[INT64, 3]\n",
      "  %onnx::MatMul_1579[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1580[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1581[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1582[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1583[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1588[INT64, 4]\n",
      "  %onnx::MatMul_1589[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1594[INT64, 4]\n",
      "  %onnx::Reshape_1599[INT64, 4]\n",
      "  %onnx::Reshape_1603[INT64, 3]\n",
      "  %onnx::MatMul_1604[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1605[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1606[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1607[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1608[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1613[INT64, 4]\n",
      "  %onnx::MatMul_1614[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1619[INT64, 4]\n",
      "  %onnx::Reshape_1624[INT64, 4]\n",
      "  %onnx::Reshape_1628[INT64, 3]\n",
      "  %onnx::MatMul_1629[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1630[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1631[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1632[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1633[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1638[INT64, 4]\n",
      "  %onnx::MatMul_1639[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1644[INT64, 4]\n",
      "  %onnx::Reshape_1649[INT64, 4]\n",
      "  %onnx::Reshape_1653[INT64, 3]\n",
      "  %onnx::MatMul_1654[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1655[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1656[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1657[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1658[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1663[INT64, 4]\n",
      "  %onnx::MatMul_1664[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1669[INT64, 4]\n",
      "  %onnx::Reshape_1674[INT64, 4]\n",
      "  %onnx::Reshape_1678[INT64, 3]\n",
      "  %onnx::MatMul_1679[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1680[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1681[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1682[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1683[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1688[INT64, 4]\n",
      "  %onnx::MatMul_1689[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1694[INT64, 4]\n",
      "  %onnx::Reshape_1699[INT64, 4]\n",
      "  %onnx::Reshape_1703[INT64, 3]\n",
      "  %onnx::MatMul_1704[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1705[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1706[FLOAT, 3072x768]\n",
      "  %onnx::MatMul_1707[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1708[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1713[INT64, 4]\n",
      "  %onnx::MatMul_1714[FLOAT, 768x768]\n",
      "  %onnx::Reshape_1719[INT64, 4]\n",
      "  %onnx::Reshape_1724[INT64, 4]\n",
      "  %onnx::Reshape_1728[INT64, 3]\n",
      "  %onnx::MatMul_1729[FLOAT, 768x768]\n",
      "  %onnx::MatMul_1730[FLOAT, 768x3072]\n",
      "  %onnx::MatMul_1731[FLOAT, 3072x768]\n",
      ") {\n",
      "  %onnx::Expand_208 = Constant[value = <Tensor>]()\n",
      "  %onnx::Mul_215 = ConstantOfShape[value = <Tensor>](%onnx::ConstantOfShape_1430)\n",
      "  %onnx::Mul_216 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Equal_217 = Mul(%onnx::Mul_215, %onnx::Mul_216)\n",
      "  %onnx::Where_218 = Equal(%onnx::Equal_1429, %onnx::Equal_217)\n",
      "  %onnx::Expand_219 = Where(%onnx::Where_218, %onnx::Mul_215, %onnx::Equal_1429)\n",
      "  %input = Expand(%onnx::Expand_208, %onnx::Expand_219)\n",
      "  %onnx::Unsqueeze_221 = Unsqueeze[axes = [1]](%input_masks)\n",
      "  %onnx::Cast_222 = Unsqueeze[axes = [2]](%onnx::Unsqueeze_221)\n",
      "  %onnx::Sub_223 = Cast[to = 1](%onnx::Cast_222)\n",
      "  %onnx::Sub_224 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_225 = Sub(%onnx::Sub_224, %onnx::Sub_223)\n",
      "  %onnx::Mul_226 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_227 = Mul(%onnx::Mul_225, %onnx::Mul_226)\n",
      "  %onnx::Add_229 = Gather(%bert.embeddings.word_embeddings.weight, %input_ids)\n",
      "  %onnx::Add_230 = Gather(%bert.embeddings.token_type_embeddings.weight, %input)\n",
      "  %onnx::Add_231 = Add(%onnx::Add_229, %onnx::Add_230)\n",
      "  %onnx::Add_232 = Gather(%bert.embeddings.position_embeddings.weight, %onnx::Gather_1431)\n",
      "  %onnx::ReduceMean_233 = Add(%onnx::Add_231, %onnx::Add_232)\n",
      "  %onnx::Sub_234 = ReduceMean[axes = [-1]](%onnx::ReduceMean_233)\n",
      "  %onnx::Pow_235 = Sub(%onnx::ReduceMean_233, %onnx::Sub_234)\n",
      "  %onnx::Pow_236 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_237 = Pow(%onnx::Pow_235, %onnx::Pow_236)\n",
      "  %onnx::Add_238 = ReduceMean[axes = [-1]](%onnx::ReduceMean_237)\n",
      "  %onnx::Add_239 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_240 = Add(%onnx::Add_238, %onnx::Add_239)\n",
      "  %onnx::Div_241 = Sqrt(%onnx::Sqrt_240)\n",
      "  %onnx::Mul_242 = Div(%onnx::Pow_235, %onnx::Div_241)\n",
      "  %onnx::Add_243 = Mul(%onnx::Mul_242, %bert.embeddings.LayerNorm.weight)\n",
      "  %input.8 = Add(%onnx::Add_243, %bert.embeddings.LayerNorm.bias)\n",
      "  %onnx::Add_246 = MatMul(%input.8, %onnx::MatMul_1432)\n",
      "  %mixed_query_layer = Add(%bert.encoder.layer.0.attention.self.query.bias, %onnx::Add_246)\n",
      "  %onnx::Add_249 = MatMul(%input.8, %onnx::MatMul_1433)\n",
      "  %onnx::Reshape_250 = Add(%bert.encoder.layer.0.attention.self.key.bias, %onnx::Add_249)\n",
      "  %onnx::Transpose_260 = Reshape(%onnx::Reshape_250, %onnx::Reshape_1438)\n",
      "  %onnx::Add_262 = MatMul(%input.8, %onnx::MatMul_1439)\n",
      "  %onnx::Reshape_263 = Add(%bert.encoder.layer.0.attention.self.value.bias, %onnx::Add_262)\n",
      "  %onnx::Transpose_273 = Reshape(%onnx::Reshape_263, %onnx::Reshape_1444)\n",
      "  %onnx::MatMul_274 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_273)\n",
      "  %onnx::Transpose_284 = Reshape(%mixed_query_layer, %onnx::Reshape_1449)\n",
      "  %onnx::MatMul_285 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_284)\n",
      "  %onnx::MatMul_286 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_260)\n",
      "  %onnx::Div_287 = MatMul(%onnx::MatMul_285, %onnx::MatMul_286)\n",
      "  %onnx::Div_288 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_289 = Div(%onnx::Div_287, %onnx::Div_288)\n",
      "  %attention_scores = Add(%onnx::Add_289, %onnx::Add_227)\n",
      "  %input.12 = Softmax[axis = 3](%attention_scores)\n",
      "  %onnx::Transpose_292 = MatMul(%input.12, %onnx::MatMul_274)\n",
      "  %onnx::Reshape_293 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_292)\n",
      "  %onnx::MatMul_301 = Reshape(%onnx::Reshape_293, %onnx::Reshape_1453)\n",
      "  %onnx::Add_303 = MatMul(%onnx::MatMul_301, %onnx::MatMul_1454)\n",
      "  %input.16 = Add(%bert.encoder.layer.0.attention.output.dense.bias, %onnx::Add_303)\n",
      "  %input.20 = Add(%input.16, %input.8)\n",
      "  %onnx::Sub_306 = ReduceMean[axes = [-1]](%input.20)\n",
      "  %onnx::Pow_307 = Sub(%input.20, %onnx::Sub_306)\n",
      "  %onnx::Pow_308 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_309 = Pow(%onnx::Pow_307, %onnx::Pow_308)\n",
      "  %onnx::Add_310 = ReduceMean[axes = [-1]](%onnx::ReduceMean_309)\n",
      "  %onnx::Add_311 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_312 = Add(%onnx::Add_310, %onnx::Add_311)\n",
      "  %onnx::Div_313 = Sqrt(%onnx::Sqrt_312)\n",
      "  %onnx::Mul_314 = Div(%onnx::Pow_307, %onnx::Div_313)\n",
      "  %onnx::Add_315 = Mul(%onnx::Mul_314, %bert.encoder.layer.0.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_316 = Add(%onnx::Add_315, %bert.encoder.layer.0.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_318 = MatMul(%onnx::MatMul_316, %onnx::MatMul_1455)\n",
      "  %onnx::Div_319 = Add(%bert.encoder.layer.0.intermediate.dense.bias, %onnx::Add_318)\n",
      "  %onnx::Div_320 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_321 = Div(%onnx::Div_319, %onnx::Div_320)\n",
      "  %onnx::Add_322 = Erf(%onnx::Erf_321)\n",
      "  %onnx::Add_323 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_324 = Add(%onnx::Add_322, %onnx::Add_323)\n",
      "  %onnx::Mul_325 = Mul(%onnx::Div_319, %onnx::Mul_324)\n",
      "  %onnx::Mul_326 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_327 = Mul(%onnx::Mul_325, %onnx::Mul_326)\n",
      "  %onnx::Add_329 = MatMul(%onnx::MatMul_327, %onnx::MatMul_1456)\n",
      "  %input.24 = Add(%bert.encoder.layer.0.output.dense.bias, %onnx::Add_329)\n",
      "  %input.28 = Add(%input.24, %onnx::MatMul_316)\n",
      "  %onnx::Sub_332 = ReduceMean[axes = [-1]](%input.28)\n",
      "  %onnx::Pow_333 = Sub(%input.28, %onnx::Sub_332)\n",
      "  %onnx::Pow_334 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_335 = Pow(%onnx::Pow_333, %onnx::Pow_334)\n",
      "  %onnx::Add_336 = ReduceMean[axes = [-1]](%onnx::ReduceMean_335)\n",
      "  %onnx::Add_337 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_338 = Add(%onnx::Add_336, %onnx::Add_337)\n",
      "  %onnx::Div_339 = Sqrt(%onnx::Sqrt_338)\n",
      "  %onnx::Mul_340 = Div(%onnx::Pow_333, %onnx::Div_339)\n",
      "  %onnx::Add_341 = Mul(%onnx::Mul_340, %bert.encoder.layer.0.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_342 = Add(%onnx::Add_341, %bert.encoder.layer.0.output.LayerNorm.bias)\n",
      "  %onnx::Add_344 = MatMul(%onnx::MatMul_342, %onnx::MatMul_1457)\n",
      "  %mixed_query_layer.3 = Add(%bert.encoder.layer.1.attention.self.query.bias, %onnx::Add_344)\n",
      "  %onnx::Add_347 = MatMul(%onnx::MatMul_342, %onnx::MatMul_1458)\n",
      "  %onnx::Reshape_348 = Add(%bert.encoder.layer.1.attention.self.key.bias, %onnx::Add_347)\n",
      "  %onnx::Transpose_358 = Reshape(%onnx::Reshape_348, %onnx::Reshape_1463)\n",
      "  %onnx::Add_360 = MatMul(%onnx::MatMul_342, %onnx::MatMul_1464)\n",
      "  %onnx::Reshape_361 = Add(%bert.encoder.layer.1.attention.self.value.bias, %onnx::Add_360)\n",
      "  %onnx::Transpose_371 = Reshape(%onnx::Reshape_361, %onnx::Reshape_1469)\n",
      "  %onnx::MatMul_372 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_371)\n",
      "  %onnx::Transpose_382 = Reshape(%mixed_query_layer.3, %onnx::Reshape_1474)\n",
      "  %onnx::MatMul_383 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_382)\n",
      "  %onnx::MatMul_384 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_358)\n",
      "  %onnx::Div_385 = MatMul(%onnx::MatMul_383, %onnx::MatMul_384)\n",
      "  %onnx::Div_386 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_387 = Div(%onnx::Div_385, %onnx::Div_386)\n",
      "  %attention_scores.3 = Add(%onnx::Add_387, %onnx::Add_227)\n",
      "  %input.32 = Softmax[axis = 3](%attention_scores.3)\n",
      "  %onnx::Transpose_390 = MatMul(%input.32, %onnx::MatMul_372)\n",
      "  %onnx::Reshape_391 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_390)\n",
      "  %onnx::MatMul_399 = Reshape(%onnx::Reshape_391, %onnx::Reshape_1478)\n",
      "  %onnx::Add_401 = MatMul(%onnx::MatMul_399, %onnx::MatMul_1479)\n",
      "  %input.36 = Add(%bert.encoder.layer.1.attention.output.dense.bias, %onnx::Add_401)\n",
      "  %input.40 = Add(%input.36, %onnx::MatMul_342)\n",
      "  %onnx::Sub_404 = ReduceMean[axes = [-1]](%input.40)\n",
      "  %onnx::Pow_405 = Sub(%input.40, %onnx::Sub_404)\n",
      "  %onnx::Pow_406 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_407 = Pow(%onnx::Pow_405, %onnx::Pow_406)\n",
      "  %onnx::Add_408 = ReduceMean[axes = [-1]](%onnx::ReduceMean_407)\n",
      "  %onnx::Add_409 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_410 = Add(%onnx::Add_408, %onnx::Add_409)\n",
      "  %onnx::Div_411 = Sqrt(%onnx::Sqrt_410)\n",
      "  %onnx::Mul_412 = Div(%onnx::Pow_405, %onnx::Div_411)\n",
      "  %onnx::Add_413 = Mul(%onnx::Mul_412, %bert.encoder.layer.1.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_414 = Add(%onnx::Add_413, %bert.encoder.layer.1.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_416 = MatMul(%onnx::MatMul_414, %onnx::MatMul_1480)\n",
      "  %onnx::Div_417 = Add(%bert.encoder.layer.1.intermediate.dense.bias, %onnx::Add_416)\n",
      "  %onnx::Div_418 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_419 = Div(%onnx::Div_417, %onnx::Div_418)\n",
      "  %onnx::Add_420 = Erf(%onnx::Erf_419)\n",
      "  %onnx::Add_421 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_422 = Add(%onnx::Add_420, %onnx::Add_421)\n",
      "  %onnx::Mul_423 = Mul(%onnx::Div_417, %onnx::Mul_422)\n",
      "  %onnx::Mul_424 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_425 = Mul(%onnx::Mul_423, %onnx::Mul_424)\n",
      "  %onnx::Add_427 = MatMul(%onnx::MatMul_425, %onnx::MatMul_1481)\n",
      "  %input.44 = Add(%bert.encoder.layer.1.output.dense.bias, %onnx::Add_427)\n",
      "  %input.48 = Add(%input.44, %onnx::MatMul_414)\n",
      "  %onnx::Sub_430 = ReduceMean[axes = [-1]](%input.48)\n",
      "  %onnx::Pow_431 = Sub(%input.48, %onnx::Sub_430)\n",
      "  %onnx::Pow_432 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_433 = Pow(%onnx::Pow_431, %onnx::Pow_432)\n",
      "  %onnx::Add_434 = ReduceMean[axes = [-1]](%onnx::ReduceMean_433)\n",
      "  %onnx::Add_435 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_436 = Add(%onnx::Add_434, %onnx::Add_435)\n",
      "  %onnx::Div_437 = Sqrt(%onnx::Sqrt_436)\n",
      "  %onnx::Mul_438 = Div(%onnx::Pow_431, %onnx::Div_437)\n",
      "  %onnx::Add_439 = Mul(%onnx::Mul_438, %bert.encoder.layer.1.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_440 = Add(%onnx::Add_439, %bert.encoder.layer.1.output.LayerNorm.bias)\n",
      "  %onnx::Add_442 = MatMul(%onnx::MatMul_440, %onnx::MatMul_1482)\n",
      "  %mixed_query_layer.7 = Add(%bert.encoder.layer.2.attention.self.query.bias, %onnx::Add_442)\n",
      "  %onnx::Add_445 = MatMul(%onnx::MatMul_440, %onnx::MatMul_1483)\n",
      "  %onnx::Reshape_446 = Add(%bert.encoder.layer.2.attention.self.key.bias, %onnx::Add_445)\n",
      "  %onnx::Transpose_456 = Reshape(%onnx::Reshape_446, %onnx::Reshape_1488)\n",
      "  %onnx::Add_458 = MatMul(%onnx::MatMul_440, %onnx::MatMul_1489)\n",
      "  %onnx::Reshape_459 = Add(%bert.encoder.layer.2.attention.self.value.bias, %onnx::Add_458)\n",
      "  %onnx::Transpose_469 = Reshape(%onnx::Reshape_459, %onnx::Reshape_1494)\n",
      "  %onnx::MatMul_470 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_469)\n",
      "  %onnx::Transpose_480 = Reshape(%mixed_query_layer.7, %onnx::Reshape_1499)\n",
      "  %onnx::MatMul_481 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_480)\n",
      "  %onnx::MatMul_482 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_456)\n",
      "  %onnx::Div_483 = MatMul(%onnx::MatMul_481, %onnx::MatMul_482)\n",
      "  %onnx::Div_484 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_485 = Div(%onnx::Div_483, %onnx::Div_484)\n",
      "  %attention_scores.7 = Add(%onnx::Add_485, %onnx::Add_227)\n",
      "  %input.52 = Softmax[axis = 3](%attention_scores.7)\n",
      "  %onnx::Transpose_488 = MatMul(%input.52, %onnx::MatMul_470)\n",
      "  %onnx::Reshape_489 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_488)\n",
      "  %onnx::MatMul_497 = Reshape(%onnx::Reshape_489, %onnx::Reshape_1503)\n",
      "  %onnx::Add_499 = MatMul(%onnx::MatMul_497, %onnx::MatMul_1504)\n",
      "  %input.56 = Add(%bert.encoder.layer.2.attention.output.dense.bias, %onnx::Add_499)\n",
      "  %input.60 = Add(%input.56, %onnx::MatMul_440)\n",
      "  %onnx::Sub_502 = ReduceMean[axes = [-1]](%input.60)\n",
      "  %onnx::Pow_503 = Sub(%input.60, %onnx::Sub_502)\n",
      "  %onnx::Pow_504 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_505 = Pow(%onnx::Pow_503, %onnx::Pow_504)\n",
      "  %onnx::Add_506 = ReduceMean[axes = [-1]](%onnx::ReduceMean_505)\n",
      "  %onnx::Add_507 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_508 = Add(%onnx::Add_506, %onnx::Add_507)\n",
      "  %onnx::Div_509 = Sqrt(%onnx::Sqrt_508)\n",
      "  %onnx::Mul_510 = Div(%onnx::Pow_503, %onnx::Div_509)\n",
      "  %onnx::Add_511 = Mul(%onnx::Mul_510, %bert.encoder.layer.2.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_512 = Add(%onnx::Add_511, %bert.encoder.layer.2.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_514 = MatMul(%onnx::MatMul_512, %onnx::MatMul_1505)\n",
      "  %onnx::Div_515 = Add(%bert.encoder.layer.2.intermediate.dense.bias, %onnx::Add_514)\n",
      "  %onnx::Div_516 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_517 = Div(%onnx::Div_515, %onnx::Div_516)\n",
      "  %onnx::Add_518 = Erf(%onnx::Erf_517)\n",
      "  %onnx::Add_519 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_520 = Add(%onnx::Add_518, %onnx::Add_519)\n",
      "  %onnx::Mul_521 = Mul(%onnx::Div_515, %onnx::Mul_520)\n",
      "  %onnx::Mul_522 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_523 = Mul(%onnx::Mul_521, %onnx::Mul_522)\n",
      "  %onnx::Add_525 = MatMul(%onnx::MatMul_523, %onnx::MatMul_1506)\n",
      "  %input.64 = Add(%bert.encoder.layer.2.output.dense.bias, %onnx::Add_525)\n",
      "  %input.68 = Add(%input.64, %onnx::MatMul_512)\n",
      "  %onnx::Sub_528 = ReduceMean[axes = [-1]](%input.68)\n",
      "  %onnx::Pow_529 = Sub(%input.68, %onnx::Sub_528)\n",
      "  %onnx::Pow_530 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_531 = Pow(%onnx::Pow_529, %onnx::Pow_530)\n",
      "  %onnx::Add_532 = ReduceMean[axes = [-1]](%onnx::ReduceMean_531)\n",
      "  %onnx::Add_533 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_534 = Add(%onnx::Add_532, %onnx::Add_533)\n",
      "  %onnx::Div_535 = Sqrt(%onnx::Sqrt_534)\n",
      "  %onnx::Mul_536 = Div(%onnx::Pow_529, %onnx::Div_535)\n",
      "  %onnx::Add_537 = Mul(%onnx::Mul_536, %bert.encoder.layer.2.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_538 = Add(%onnx::Add_537, %bert.encoder.layer.2.output.LayerNorm.bias)\n",
      "  %onnx::Add_540 = MatMul(%onnx::MatMul_538, %onnx::MatMul_1507)\n",
      "  %mixed_query_layer.11 = Add(%bert.encoder.layer.3.attention.self.query.bias, %onnx::Add_540)\n",
      "  %onnx::Add_543 = MatMul(%onnx::MatMul_538, %onnx::MatMul_1508)\n",
      "  %onnx::Reshape_544 = Add(%bert.encoder.layer.3.attention.self.key.bias, %onnx::Add_543)\n",
      "  %onnx::Transpose_554 = Reshape(%onnx::Reshape_544, %onnx::Reshape_1513)\n",
      "  %onnx::Add_556 = MatMul(%onnx::MatMul_538, %onnx::MatMul_1514)\n",
      "  %onnx::Reshape_557 = Add(%bert.encoder.layer.3.attention.self.value.bias, %onnx::Add_556)\n",
      "  %onnx::Transpose_567 = Reshape(%onnx::Reshape_557, %onnx::Reshape_1519)\n",
      "  %onnx::MatMul_568 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_567)\n",
      "  %onnx::Transpose_578 = Reshape(%mixed_query_layer.11, %onnx::Reshape_1524)\n",
      "  %onnx::MatMul_579 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_578)\n",
      "  %onnx::MatMul_580 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_554)\n",
      "  %onnx::Div_581 = MatMul(%onnx::MatMul_579, %onnx::MatMul_580)\n",
      "  %onnx::Div_582 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_583 = Div(%onnx::Div_581, %onnx::Div_582)\n",
      "  %attention_scores.11 = Add(%onnx::Add_583, %onnx::Add_227)\n",
      "  %input.72 = Softmax[axis = 3](%attention_scores.11)\n",
      "  %onnx::Transpose_586 = MatMul(%input.72, %onnx::MatMul_568)\n",
      "  %onnx::Reshape_587 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_586)\n",
      "  %onnx::MatMul_595 = Reshape(%onnx::Reshape_587, %onnx::Reshape_1528)\n",
      "  %onnx::Add_597 = MatMul(%onnx::MatMul_595, %onnx::MatMul_1529)\n",
      "  %input.76 = Add(%bert.encoder.layer.3.attention.output.dense.bias, %onnx::Add_597)\n",
      "  %input.80 = Add(%input.76, %onnx::MatMul_538)\n",
      "  %onnx::Sub_600 = ReduceMean[axes = [-1]](%input.80)\n",
      "  %onnx::Pow_601 = Sub(%input.80, %onnx::Sub_600)\n",
      "  %onnx::Pow_602 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_603 = Pow(%onnx::Pow_601, %onnx::Pow_602)\n",
      "  %onnx::Add_604 = ReduceMean[axes = [-1]](%onnx::ReduceMean_603)\n",
      "  %onnx::Add_605 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_606 = Add(%onnx::Add_604, %onnx::Add_605)\n",
      "  %onnx::Div_607 = Sqrt(%onnx::Sqrt_606)\n",
      "  %onnx::Mul_608 = Div(%onnx::Pow_601, %onnx::Div_607)\n",
      "  %onnx::Add_609 = Mul(%onnx::Mul_608, %bert.encoder.layer.3.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_610 = Add(%onnx::Add_609, %bert.encoder.layer.3.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_612 = MatMul(%onnx::MatMul_610, %onnx::MatMul_1530)\n",
      "  %onnx::Div_613 = Add(%bert.encoder.layer.3.intermediate.dense.bias, %onnx::Add_612)\n",
      "  %onnx::Div_614 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_615 = Div(%onnx::Div_613, %onnx::Div_614)\n",
      "  %onnx::Add_616 = Erf(%onnx::Erf_615)\n",
      "  %onnx::Add_617 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_618 = Add(%onnx::Add_616, %onnx::Add_617)\n",
      "  %onnx::Mul_619 = Mul(%onnx::Div_613, %onnx::Mul_618)\n",
      "  %onnx::Mul_620 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_621 = Mul(%onnx::Mul_619, %onnx::Mul_620)\n",
      "  %onnx::Add_623 = MatMul(%onnx::MatMul_621, %onnx::MatMul_1531)\n",
      "  %input.84 = Add(%bert.encoder.layer.3.output.dense.bias, %onnx::Add_623)\n",
      "  %input.88 = Add(%input.84, %onnx::MatMul_610)\n",
      "  %onnx::Sub_626 = ReduceMean[axes = [-1]](%input.88)\n",
      "  %onnx::Pow_627 = Sub(%input.88, %onnx::Sub_626)\n",
      "  %onnx::Pow_628 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_629 = Pow(%onnx::Pow_627, %onnx::Pow_628)\n",
      "  %onnx::Add_630 = ReduceMean[axes = [-1]](%onnx::ReduceMean_629)\n",
      "  %onnx::Add_631 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_632 = Add(%onnx::Add_630, %onnx::Add_631)\n",
      "  %onnx::Div_633 = Sqrt(%onnx::Sqrt_632)\n",
      "  %onnx::Mul_634 = Div(%onnx::Pow_627, %onnx::Div_633)\n",
      "  %onnx::Add_635 = Mul(%onnx::Mul_634, %bert.encoder.layer.3.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_636 = Add(%onnx::Add_635, %bert.encoder.layer.3.output.LayerNorm.bias)\n",
      "  %onnx::Add_638 = MatMul(%onnx::MatMul_636, %onnx::MatMul_1532)\n",
      "  %mixed_query_layer.15 = Add(%bert.encoder.layer.4.attention.self.query.bias, %onnx::Add_638)\n",
      "  %onnx::Add_641 = MatMul(%onnx::MatMul_636, %onnx::MatMul_1533)\n",
      "  %onnx::Reshape_642 = Add(%bert.encoder.layer.4.attention.self.key.bias, %onnx::Add_641)\n",
      "  %onnx::Transpose_652 = Reshape(%onnx::Reshape_642, %onnx::Reshape_1538)\n",
      "  %onnx::Add_654 = MatMul(%onnx::MatMul_636, %onnx::MatMul_1539)\n",
      "  %onnx::Reshape_655 = Add(%bert.encoder.layer.4.attention.self.value.bias, %onnx::Add_654)\n",
      "  %onnx::Transpose_665 = Reshape(%onnx::Reshape_655, %onnx::Reshape_1544)\n",
      "  %onnx::MatMul_666 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_665)\n",
      "  %onnx::Transpose_676 = Reshape(%mixed_query_layer.15, %onnx::Reshape_1549)\n",
      "  %onnx::MatMul_677 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_676)\n",
      "  %onnx::MatMul_678 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_652)\n",
      "  %onnx::Div_679 = MatMul(%onnx::MatMul_677, %onnx::MatMul_678)\n",
      "  %onnx::Div_680 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_681 = Div(%onnx::Div_679, %onnx::Div_680)\n",
      "  %attention_scores.15 = Add(%onnx::Add_681, %onnx::Add_227)\n",
      "  %input.92 = Softmax[axis = 3](%attention_scores.15)\n",
      "  %onnx::Transpose_684 = MatMul(%input.92, %onnx::MatMul_666)\n",
      "  %onnx::Reshape_685 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_684)\n",
      "  %onnx::MatMul_693 = Reshape(%onnx::Reshape_685, %onnx::Reshape_1553)\n",
      "  %onnx::Add_695 = MatMul(%onnx::MatMul_693, %onnx::MatMul_1554)\n",
      "  %input.96 = Add(%bert.encoder.layer.4.attention.output.dense.bias, %onnx::Add_695)\n",
      "  %input.100 = Add(%input.96, %onnx::MatMul_636)\n",
      "  %onnx::Sub_698 = ReduceMean[axes = [-1]](%input.100)\n",
      "  %onnx::Pow_699 = Sub(%input.100, %onnx::Sub_698)\n",
      "  %onnx::Pow_700 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_701 = Pow(%onnx::Pow_699, %onnx::Pow_700)\n",
      "  %onnx::Add_702 = ReduceMean[axes = [-1]](%onnx::ReduceMean_701)\n",
      "  %onnx::Add_703 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_704 = Add(%onnx::Add_702, %onnx::Add_703)\n",
      "  %onnx::Div_705 = Sqrt(%onnx::Sqrt_704)\n",
      "  %onnx::Mul_706 = Div(%onnx::Pow_699, %onnx::Div_705)\n",
      "  %onnx::Add_707 = Mul(%onnx::Mul_706, %bert.encoder.layer.4.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_708 = Add(%onnx::Add_707, %bert.encoder.layer.4.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_710 = MatMul(%onnx::MatMul_708, %onnx::MatMul_1555)\n",
      "  %onnx::Div_711 = Add(%bert.encoder.layer.4.intermediate.dense.bias, %onnx::Add_710)\n",
      "  %onnx::Div_712 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_713 = Div(%onnx::Div_711, %onnx::Div_712)\n",
      "  %onnx::Add_714 = Erf(%onnx::Erf_713)\n",
      "  %onnx::Add_715 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_716 = Add(%onnx::Add_714, %onnx::Add_715)\n",
      "  %onnx::Mul_717 = Mul(%onnx::Div_711, %onnx::Mul_716)\n",
      "  %onnx::Mul_718 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_719 = Mul(%onnx::Mul_717, %onnx::Mul_718)\n",
      "  %onnx::Add_721 = MatMul(%onnx::MatMul_719, %onnx::MatMul_1556)\n",
      "  %input.104 = Add(%bert.encoder.layer.4.output.dense.bias, %onnx::Add_721)\n",
      "  %input.108 = Add(%input.104, %onnx::MatMul_708)\n",
      "  %onnx::Sub_724 = ReduceMean[axes = [-1]](%input.108)\n",
      "  %onnx::Pow_725 = Sub(%input.108, %onnx::Sub_724)\n",
      "  %onnx::Pow_726 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_727 = Pow(%onnx::Pow_725, %onnx::Pow_726)\n",
      "  %onnx::Add_728 = ReduceMean[axes = [-1]](%onnx::ReduceMean_727)\n",
      "  %onnx::Add_729 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_730 = Add(%onnx::Add_728, %onnx::Add_729)\n",
      "  %onnx::Div_731 = Sqrt(%onnx::Sqrt_730)\n",
      "  %onnx::Mul_732 = Div(%onnx::Pow_725, %onnx::Div_731)\n",
      "  %onnx::Add_733 = Mul(%onnx::Mul_732, %bert.encoder.layer.4.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_734 = Add(%onnx::Add_733, %bert.encoder.layer.4.output.LayerNorm.bias)\n",
      "  %onnx::Add_736 = MatMul(%onnx::MatMul_734, %onnx::MatMul_1557)\n",
      "  %mixed_query_layer.19 = Add(%bert.encoder.layer.5.attention.self.query.bias, %onnx::Add_736)\n",
      "  %onnx::Add_739 = MatMul(%onnx::MatMul_734, %onnx::MatMul_1558)\n",
      "  %onnx::Reshape_740 = Add(%bert.encoder.layer.5.attention.self.key.bias, %onnx::Add_739)\n",
      "  %onnx::Transpose_750 = Reshape(%onnx::Reshape_740, %onnx::Reshape_1563)\n",
      "  %onnx::Add_752 = MatMul(%onnx::MatMul_734, %onnx::MatMul_1564)\n",
      "  %onnx::Reshape_753 = Add(%bert.encoder.layer.5.attention.self.value.bias, %onnx::Add_752)\n",
      "  %onnx::Transpose_763 = Reshape(%onnx::Reshape_753, %onnx::Reshape_1569)\n",
      "  %onnx::MatMul_764 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_763)\n",
      "  %onnx::Transpose_774 = Reshape(%mixed_query_layer.19, %onnx::Reshape_1574)\n",
      "  %onnx::MatMul_775 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_774)\n",
      "  %onnx::MatMul_776 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_750)\n",
      "  %onnx::Div_777 = MatMul(%onnx::MatMul_775, %onnx::MatMul_776)\n",
      "  %onnx::Div_778 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_779 = Div(%onnx::Div_777, %onnx::Div_778)\n",
      "  %attention_scores.19 = Add(%onnx::Add_779, %onnx::Add_227)\n",
      "  %input.112 = Softmax[axis = 3](%attention_scores.19)\n",
      "  %onnx::Transpose_782 = MatMul(%input.112, %onnx::MatMul_764)\n",
      "  %onnx::Reshape_783 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_782)\n",
      "  %onnx::MatMul_791 = Reshape(%onnx::Reshape_783, %onnx::Reshape_1578)\n",
      "  %onnx::Add_793 = MatMul(%onnx::MatMul_791, %onnx::MatMul_1579)\n",
      "  %input.116 = Add(%bert.encoder.layer.5.attention.output.dense.bias, %onnx::Add_793)\n",
      "  %input.120 = Add(%input.116, %onnx::MatMul_734)\n",
      "  %onnx::Sub_796 = ReduceMean[axes = [-1]](%input.120)\n",
      "  %onnx::Pow_797 = Sub(%input.120, %onnx::Sub_796)\n",
      "  %onnx::Pow_798 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_799 = Pow(%onnx::Pow_797, %onnx::Pow_798)\n",
      "  %onnx::Add_800 = ReduceMean[axes = [-1]](%onnx::ReduceMean_799)\n",
      "  %onnx::Add_801 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_802 = Add(%onnx::Add_800, %onnx::Add_801)\n",
      "  %onnx::Div_803 = Sqrt(%onnx::Sqrt_802)\n",
      "  %onnx::Mul_804 = Div(%onnx::Pow_797, %onnx::Div_803)\n",
      "  %onnx::Add_805 = Mul(%onnx::Mul_804, %bert.encoder.layer.5.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_806 = Add(%onnx::Add_805, %bert.encoder.layer.5.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_808 = MatMul(%onnx::MatMul_806, %onnx::MatMul_1580)\n",
      "  %onnx::Div_809 = Add(%bert.encoder.layer.5.intermediate.dense.bias, %onnx::Add_808)\n",
      "  %onnx::Div_810 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_811 = Div(%onnx::Div_809, %onnx::Div_810)\n",
      "  %onnx::Add_812 = Erf(%onnx::Erf_811)\n",
      "  %onnx::Add_813 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_814 = Add(%onnx::Add_812, %onnx::Add_813)\n",
      "  %onnx::Mul_815 = Mul(%onnx::Div_809, %onnx::Mul_814)\n",
      "  %onnx::Mul_816 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_817 = Mul(%onnx::Mul_815, %onnx::Mul_816)\n",
      "  %onnx::Add_819 = MatMul(%onnx::MatMul_817, %onnx::MatMul_1581)\n",
      "  %input.124 = Add(%bert.encoder.layer.5.output.dense.bias, %onnx::Add_819)\n",
      "  %input.128 = Add(%input.124, %onnx::MatMul_806)\n",
      "  %onnx::Sub_822 = ReduceMean[axes = [-1]](%input.128)\n",
      "  %onnx::Pow_823 = Sub(%input.128, %onnx::Sub_822)\n",
      "  %onnx::Pow_824 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_825 = Pow(%onnx::Pow_823, %onnx::Pow_824)\n",
      "  %onnx::Add_826 = ReduceMean[axes = [-1]](%onnx::ReduceMean_825)\n",
      "  %onnx::Add_827 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_828 = Add(%onnx::Add_826, %onnx::Add_827)\n",
      "  %onnx::Div_829 = Sqrt(%onnx::Sqrt_828)\n",
      "  %onnx::Mul_830 = Div(%onnx::Pow_823, %onnx::Div_829)\n",
      "  %onnx::Add_831 = Mul(%onnx::Mul_830, %bert.encoder.layer.5.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_832 = Add(%onnx::Add_831, %bert.encoder.layer.5.output.LayerNorm.bias)\n",
      "  %onnx::Add_834 = MatMul(%onnx::MatMul_832, %onnx::MatMul_1582)\n",
      "  %mixed_query_layer.23 = Add(%bert.encoder.layer.6.attention.self.query.bias, %onnx::Add_834)\n",
      "  %onnx::Add_837 = MatMul(%onnx::MatMul_832, %onnx::MatMul_1583)\n",
      "  %onnx::Reshape_838 = Add(%bert.encoder.layer.6.attention.self.key.bias, %onnx::Add_837)\n",
      "  %onnx::Transpose_848 = Reshape(%onnx::Reshape_838, %onnx::Reshape_1588)\n",
      "  %onnx::Add_850 = MatMul(%onnx::MatMul_832, %onnx::MatMul_1589)\n",
      "  %onnx::Reshape_851 = Add(%bert.encoder.layer.6.attention.self.value.bias, %onnx::Add_850)\n",
      "  %onnx::Transpose_861 = Reshape(%onnx::Reshape_851, %onnx::Reshape_1594)\n",
      "  %onnx::MatMul_862 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_861)\n",
      "  %onnx::Transpose_872 = Reshape(%mixed_query_layer.23, %onnx::Reshape_1599)\n",
      "  %onnx::MatMul_873 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_872)\n",
      "  %onnx::MatMul_874 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_848)\n",
      "  %onnx::Div_875 = MatMul(%onnx::MatMul_873, %onnx::MatMul_874)\n",
      "  %onnx::Div_876 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_877 = Div(%onnx::Div_875, %onnx::Div_876)\n",
      "  %attention_scores.23 = Add(%onnx::Add_877, %onnx::Add_227)\n",
      "  %input.132 = Softmax[axis = 3](%attention_scores.23)\n",
      "  %onnx::Transpose_880 = MatMul(%input.132, %onnx::MatMul_862)\n",
      "  %onnx::Reshape_881 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_880)\n",
      "  %onnx::MatMul_889 = Reshape(%onnx::Reshape_881, %onnx::Reshape_1603)\n",
      "  %onnx::Add_891 = MatMul(%onnx::MatMul_889, %onnx::MatMul_1604)\n",
      "  %input.136 = Add(%bert.encoder.layer.6.attention.output.dense.bias, %onnx::Add_891)\n",
      "  %input.140 = Add(%input.136, %onnx::MatMul_832)\n",
      "  %onnx::Sub_894 = ReduceMean[axes = [-1]](%input.140)\n",
      "  %onnx::Pow_895 = Sub(%input.140, %onnx::Sub_894)\n",
      "  %onnx::Pow_896 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_897 = Pow(%onnx::Pow_895, %onnx::Pow_896)\n",
      "  %onnx::Add_898 = ReduceMean[axes = [-1]](%onnx::ReduceMean_897)\n",
      "  %onnx::Add_899 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_900 = Add(%onnx::Add_898, %onnx::Add_899)\n",
      "  %onnx::Div_901 = Sqrt(%onnx::Sqrt_900)\n",
      "  %onnx::Mul_902 = Div(%onnx::Pow_895, %onnx::Div_901)\n",
      "  %onnx::Add_903 = Mul(%onnx::Mul_902, %bert.encoder.layer.6.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_904 = Add(%onnx::Add_903, %bert.encoder.layer.6.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_906 = MatMul(%onnx::MatMul_904, %onnx::MatMul_1605)\n",
      "  %onnx::Div_907 = Add(%bert.encoder.layer.6.intermediate.dense.bias, %onnx::Add_906)\n",
      "  %onnx::Div_908 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_909 = Div(%onnx::Div_907, %onnx::Div_908)\n",
      "  %onnx::Add_910 = Erf(%onnx::Erf_909)\n",
      "  %onnx::Add_911 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_912 = Add(%onnx::Add_910, %onnx::Add_911)\n",
      "  %onnx::Mul_913 = Mul(%onnx::Div_907, %onnx::Mul_912)\n",
      "  %onnx::Mul_914 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_915 = Mul(%onnx::Mul_913, %onnx::Mul_914)\n",
      "  %onnx::Add_917 = MatMul(%onnx::MatMul_915, %onnx::MatMul_1606)\n",
      "  %input.144 = Add(%bert.encoder.layer.6.output.dense.bias, %onnx::Add_917)\n",
      "  %input.148 = Add(%input.144, %onnx::MatMul_904)\n",
      "  %onnx::Sub_920 = ReduceMean[axes = [-1]](%input.148)\n",
      "  %onnx::Pow_921 = Sub(%input.148, %onnx::Sub_920)\n",
      "  %onnx::Pow_922 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_923 = Pow(%onnx::Pow_921, %onnx::Pow_922)\n",
      "  %onnx::Add_924 = ReduceMean[axes = [-1]](%onnx::ReduceMean_923)\n",
      "  %onnx::Add_925 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_926 = Add(%onnx::Add_924, %onnx::Add_925)\n",
      "  %onnx::Div_927 = Sqrt(%onnx::Sqrt_926)\n",
      "  %onnx::Mul_928 = Div(%onnx::Pow_921, %onnx::Div_927)\n",
      "  %onnx::Add_929 = Mul(%onnx::Mul_928, %bert.encoder.layer.6.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_930 = Add(%onnx::Add_929, %bert.encoder.layer.6.output.LayerNorm.bias)\n",
      "  %onnx::Add_932 = MatMul(%onnx::MatMul_930, %onnx::MatMul_1607)\n",
      "  %mixed_query_layer.27 = Add(%bert.encoder.layer.7.attention.self.query.bias, %onnx::Add_932)\n",
      "  %onnx::Add_935 = MatMul(%onnx::MatMul_930, %onnx::MatMul_1608)\n",
      "  %onnx::Reshape_936 = Add(%bert.encoder.layer.7.attention.self.key.bias, %onnx::Add_935)\n",
      "  %onnx::Transpose_946 = Reshape(%onnx::Reshape_936, %onnx::Reshape_1613)\n",
      "  %onnx::Add_948 = MatMul(%onnx::MatMul_930, %onnx::MatMul_1614)\n",
      "  %onnx::Reshape_949 = Add(%bert.encoder.layer.7.attention.self.value.bias, %onnx::Add_948)\n",
      "  %onnx::Transpose_959 = Reshape(%onnx::Reshape_949, %onnx::Reshape_1619)\n",
      "  %onnx::MatMul_960 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_959)\n",
      "  %onnx::Transpose_970 = Reshape(%mixed_query_layer.27, %onnx::Reshape_1624)\n",
      "  %onnx::MatMul_971 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_970)\n",
      "  %onnx::MatMul_972 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_946)\n",
      "  %onnx::Div_973 = MatMul(%onnx::MatMul_971, %onnx::MatMul_972)\n",
      "  %onnx::Div_974 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_975 = Div(%onnx::Div_973, %onnx::Div_974)\n",
      "  %attention_scores.27 = Add(%onnx::Add_975, %onnx::Add_227)\n",
      "  %input.152 = Softmax[axis = 3](%attention_scores.27)\n",
      "  %onnx::Transpose_978 = MatMul(%input.152, %onnx::MatMul_960)\n",
      "  %onnx::Reshape_979 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_978)\n",
      "  %onnx::MatMul_987 = Reshape(%onnx::Reshape_979, %onnx::Reshape_1628)\n",
      "  %onnx::Add_989 = MatMul(%onnx::MatMul_987, %onnx::MatMul_1629)\n",
      "  %input.156 = Add(%bert.encoder.layer.7.attention.output.dense.bias, %onnx::Add_989)\n",
      "  %input.160 = Add(%input.156, %onnx::MatMul_930)\n",
      "  %onnx::Sub_992 = ReduceMean[axes = [-1]](%input.160)\n",
      "  %onnx::Pow_993 = Sub(%input.160, %onnx::Sub_992)\n",
      "  %onnx::Pow_994 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_995 = Pow(%onnx::Pow_993, %onnx::Pow_994)\n",
      "  %onnx::Add_996 = ReduceMean[axes = [-1]](%onnx::ReduceMean_995)\n",
      "  %onnx::Add_997 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_998 = Add(%onnx::Add_996, %onnx::Add_997)\n",
      "  %onnx::Div_999 = Sqrt(%onnx::Sqrt_998)\n",
      "  %onnx::Mul_1000 = Div(%onnx::Pow_993, %onnx::Div_999)\n",
      "  %onnx::Add_1001 = Mul(%onnx::Mul_1000, %bert.encoder.layer.7.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1002 = Add(%onnx::Add_1001, %bert.encoder.layer.7.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1004 = MatMul(%onnx::MatMul_1002, %onnx::MatMul_1630)\n",
      "  %onnx::Div_1005 = Add(%bert.encoder.layer.7.intermediate.dense.bias, %onnx::Add_1004)\n",
      "  %onnx::Div_1006 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1007 = Div(%onnx::Div_1005, %onnx::Div_1006)\n",
      "  %onnx::Add_1008 = Erf(%onnx::Erf_1007)\n",
      "  %onnx::Add_1009 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1010 = Add(%onnx::Add_1008, %onnx::Add_1009)\n",
      "  %onnx::Mul_1011 = Mul(%onnx::Div_1005, %onnx::Mul_1010)\n",
      "  %onnx::Mul_1012 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1013 = Mul(%onnx::Mul_1011, %onnx::Mul_1012)\n",
      "  %onnx::Add_1015 = MatMul(%onnx::MatMul_1013, %onnx::MatMul_1631)\n",
      "  %input.164 = Add(%bert.encoder.layer.7.output.dense.bias, %onnx::Add_1015)\n",
      "  %input.168 = Add(%input.164, %onnx::MatMul_1002)\n",
      "  %onnx::Sub_1018 = ReduceMean[axes = [-1]](%input.168)\n",
      "  %onnx::Pow_1019 = Sub(%input.168, %onnx::Sub_1018)\n",
      "  %onnx::Pow_1020 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1021 = Pow(%onnx::Pow_1019, %onnx::Pow_1020)\n",
      "  %onnx::Add_1022 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1021)\n",
      "  %onnx::Add_1023 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1024 = Add(%onnx::Add_1022, %onnx::Add_1023)\n",
      "  %onnx::Div_1025 = Sqrt(%onnx::Sqrt_1024)\n",
      "  %onnx::Mul_1026 = Div(%onnx::Pow_1019, %onnx::Div_1025)\n",
      "  %onnx::Add_1027 = Mul(%onnx::Mul_1026, %bert.encoder.layer.7.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1028 = Add(%onnx::Add_1027, %bert.encoder.layer.7.output.LayerNorm.bias)\n",
      "  %onnx::Add_1030 = MatMul(%onnx::MatMul_1028, %onnx::MatMul_1632)\n",
      "  %mixed_query_layer.31 = Add(%bert.encoder.layer.8.attention.self.query.bias, %onnx::Add_1030)\n",
      "  %onnx::Add_1033 = MatMul(%onnx::MatMul_1028, %onnx::MatMul_1633)\n",
      "  %onnx::Reshape_1034 = Add(%bert.encoder.layer.8.attention.self.key.bias, %onnx::Add_1033)\n",
      "  %onnx::Transpose_1044 = Reshape(%onnx::Reshape_1034, %onnx::Reshape_1638)\n",
      "  %onnx::Add_1046 = MatMul(%onnx::MatMul_1028, %onnx::MatMul_1639)\n",
      "  %onnx::Reshape_1047 = Add(%bert.encoder.layer.8.attention.self.value.bias, %onnx::Add_1046)\n",
      "  %onnx::Transpose_1057 = Reshape(%onnx::Reshape_1047, %onnx::Reshape_1644)\n",
      "  %onnx::MatMul_1058 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1057)\n",
      "  %onnx::Transpose_1068 = Reshape(%mixed_query_layer.31, %onnx::Reshape_1649)\n",
      "  %onnx::MatMul_1069 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1068)\n",
      "  %onnx::MatMul_1070 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1044)\n",
      "  %onnx::Div_1071 = MatMul(%onnx::MatMul_1069, %onnx::MatMul_1070)\n",
      "  %onnx::Div_1072 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1073 = Div(%onnx::Div_1071, %onnx::Div_1072)\n",
      "  %attention_scores.31 = Add(%onnx::Add_1073, %onnx::Add_227)\n",
      "  %input.172 = Softmax[axis = 3](%attention_scores.31)\n",
      "  %onnx::Transpose_1076 = MatMul(%input.172, %onnx::MatMul_1058)\n",
      "  %onnx::Reshape_1077 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1076)\n",
      "  %onnx::MatMul_1085 = Reshape(%onnx::Reshape_1077, %onnx::Reshape_1653)\n",
      "  %onnx::Add_1087 = MatMul(%onnx::MatMul_1085, %onnx::MatMul_1654)\n",
      "  %input.176 = Add(%bert.encoder.layer.8.attention.output.dense.bias, %onnx::Add_1087)\n",
      "  %input.180 = Add(%input.176, %onnx::MatMul_1028)\n",
      "  %onnx::Sub_1090 = ReduceMean[axes = [-1]](%input.180)\n",
      "  %onnx::Pow_1091 = Sub(%input.180, %onnx::Sub_1090)\n",
      "  %onnx::Pow_1092 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1093 = Pow(%onnx::Pow_1091, %onnx::Pow_1092)\n",
      "  %onnx::Add_1094 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1093)\n",
      "  %onnx::Add_1095 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1096 = Add(%onnx::Add_1094, %onnx::Add_1095)\n",
      "  %onnx::Div_1097 = Sqrt(%onnx::Sqrt_1096)\n",
      "  %onnx::Mul_1098 = Div(%onnx::Pow_1091, %onnx::Div_1097)\n",
      "  %onnx::Add_1099 = Mul(%onnx::Mul_1098, %bert.encoder.layer.8.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1100 = Add(%onnx::Add_1099, %bert.encoder.layer.8.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1102 = MatMul(%onnx::MatMul_1100, %onnx::MatMul_1655)\n",
      "  %onnx::Div_1103 = Add(%bert.encoder.layer.8.intermediate.dense.bias, %onnx::Add_1102)\n",
      "  %onnx::Div_1104 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1105 = Div(%onnx::Div_1103, %onnx::Div_1104)\n",
      "  %onnx::Add_1106 = Erf(%onnx::Erf_1105)\n",
      "  %onnx::Add_1107 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1108 = Add(%onnx::Add_1106, %onnx::Add_1107)\n",
      "  %onnx::Mul_1109 = Mul(%onnx::Div_1103, %onnx::Mul_1108)\n",
      "  %onnx::Mul_1110 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1111 = Mul(%onnx::Mul_1109, %onnx::Mul_1110)\n",
      "  %onnx::Add_1113 = MatMul(%onnx::MatMul_1111, %onnx::MatMul_1656)\n",
      "  %input.184 = Add(%bert.encoder.layer.8.output.dense.bias, %onnx::Add_1113)\n",
      "  %input.188 = Add(%input.184, %onnx::MatMul_1100)\n",
      "  %onnx::Sub_1116 = ReduceMean[axes = [-1]](%input.188)\n",
      "  %onnx::Pow_1117 = Sub(%input.188, %onnx::Sub_1116)\n",
      "  %onnx::Pow_1118 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1119 = Pow(%onnx::Pow_1117, %onnx::Pow_1118)\n",
      "  %onnx::Add_1120 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1119)\n",
      "  %onnx::Add_1121 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1122 = Add(%onnx::Add_1120, %onnx::Add_1121)\n",
      "  %onnx::Div_1123 = Sqrt(%onnx::Sqrt_1122)\n",
      "  %onnx::Mul_1124 = Div(%onnx::Pow_1117, %onnx::Div_1123)\n",
      "  %onnx::Add_1125 = Mul(%onnx::Mul_1124, %bert.encoder.layer.8.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1126 = Add(%onnx::Add_1125, %bert.encoder.layer.8.output.LayerNorm.bias)\n",
      "  %onnx::Add_1128 = MatMul(%onnx::MatMul_1126, %onnx::MatMul_1657)\n",
      "  %mixed_query_layer.35 = Add(%bert.encoder.layer.9.attention.self.query.bias, %onnx::Add_1128)\n",
      "  %onnx::Add_1131 = MatMul(%onnx::MatMul_1126, %onnx::MatMul_1658)\n",
      "  %onnx::Reshape_1132 = Add(%bert.encoder.layer.9.attention.self.key.bias, %onnx::Add_1131)\n",
      "  %onnx::Transpose_1142 = Reshape(%onnx::Reshape_1132, %onnx::Reshape_1663)\n",
      "  %onnx::Add_1144 = MatMul(%onnx::MatMul_1126, %onnx::MatMul_1664)\n",
      "  %onnx::Reshape_1145 = Add(%bert.encoder.layer.9.attention.self.value.bias, %onnx::Add_1144)\n",
      "  %onnx::Transpose_1155 = Reshape(%onnx::Reshape_1145, %onnx::Reshape_1669)\n",
      "  %onnx::MatMul_1156 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1155)\n",
      "  %onnx::Transpose_1166 = Reshape(%mixed_query_layer.35, %onnx::Reshape_1674)\n",
      "  %onnx::MatMul_1167 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1166)\n",
      "  %onnx::MatMul_1168 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1142)\n",
      "  %onnx::Div_1169 = MatMul(%onnx::MatMul_1167, %onnx::MatMul_1168)\n",
      "  %onnx::Div_1170 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1171 = Div(%onnx::Div_1169, %onnx::Div_1170)\n",
      "  %attention_scores.35 = Add(%onnx::Add_1171, %onnx::Add_227)\n",
      "  %input.192 = Softmax[axis = 3](%attention_scores.35)\n",
      "  %onnx::Transpose_1174 = MatMul(%input.192, %onnx::MatMul_1156)\n",
      "  %onnx::Reshape_1175 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1174)\n",
      "  %onnx::MatMul_1183 = Reshape(%onnx::Reshape_1175, %onnx::Reshape_1678)\n",
      "  %onnx::Add_1185 = MatMul(%onnx::MatMul_1183, %onnx::MatMul_1679)\n",
      "  %input.196 = Add(%bert.encoder.layer.9.attention.output.dense.bias, %onnx::Add_1185)\n",
      "  %input.200 = Add(%input.196, %onnx::MatMul_1126)\n",
      "  %onnx::Sub_1188 = ReduceMean[axes = [-1]](%input.200)\n",
      "  %onnx::Pow_1189 = Sub(%input.200, %onnx::Sub_1188)\n",
      "  %onnx::Pow_1190 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1191 = Pow(%onnx::Pow_1189, %onnx::Pow_1190)\n",
      "  %onnx::Add_1192 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1191)\n",
      "  %onnx::Add_1193 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1194 = Add(%onnx::Add_1192, %onnx::Add_1193)\n",
      "  %onnx::Div_1195 = Sqrt(%onnx::Sqrt_1194)\n",
      "  %onnx::Mul_1196 = Div(%onnx::Pow_1189, %onnx::Div_1195)\n",
      "  %onnx::Add_1197 = Mul(%onnx::Mul_1196, %bert.encoder.layer.9.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1198 = Add(%onnx::Add_1197, %bert.encoder.layer.9.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1200 = MatMul(%onnx::MatMul_1198, %onnx::MatMul_1680)\n",
      "  %onnx::Div_1201 = Add(%bert.encoder.layer.9.intermediate.dense.bias, %onnx::Add_1200)\n",
      "  %onnx::Div_1202 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1203 = Div(%onnx::Div_1201, %onnx::Div_1202)\n",
      "  %onnx::Add_1204 = Erf(%onnx::Erf_1203)\n",
      "  %onnx::Add_1205 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1206 = Add(%onnx::Add_1204, %onnx::Add_1205)\n",
      "  %onnx::Mul_1207 = Mul(%onnx::Div_1201, %onnx::Mul_1206)\n",
      "  %onnx::Mul_1208 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1209 = Mul(%onnx::Mul_1207, %onnx::Mul_1208)\n",
      "  %onnx::Add_1211 = MatMul(%onnx::MatMul_1209, %onnx::MatMul_1681)\n",
      "  %input.204 = Add(%bert.encoder.layer.9.output.dense.bias, %onnx::Add_1211)\n",
      "  %input.208 = Add(%input.204, %onnx::MatMul_1198)\n",
      "  %onnx::Sub_1214 = ReduceMean[axes = [-1]](%input.208)\n",
      "  %onnx::Pow_1215 = Sub(%input.208, %onnx::Sub_1214)\n",
      "  %onnx::Pow_1216 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1217 = Pow(%onnx::Pow_1215, %onnx::Pow_1216)\n",
      "  %onnx::Add_1218 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1217)\n",
      "  %onnx::Add_1219 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1220 = Add(%onnx::Add_1218, %onnx::Add_1219)\n",
      "  %onnx::Div_1221 = Sqrt(%onnx::Sqrt_1220)\n",
      "  %onnx::Mul_1222 = Div(%onnx::Pow_1215, %onnx::Div_1221)\n",
      "  %onnx::Add_1223 = Mul(%onnx::Mul_1222, %bert.encoder.layer.9.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1224 = Add(%onnx::Add_1223, %bert.encoder.layer.9.output.LayerNorm.bias)\n",
      "  %onnx::Add_1226 = MatMul(%onnx::MatMul_1224, %onnx::MatMul_1682)\n",
      "  %mixed_query_layer.39 = Add(%bert.encoder.layer.10.attention.self.query.bias, %onnx::Add_1226)\n",
      "  %onnx::Add_1229 = MatMul(%onnx::MatMul_1224, %onnx::MatMul_1683)\n",
      "  %onnx::Reshape_1230 = Add(%bert.encoder.layer.10.attention.self.key.bias, %onnx::Add_1229)\n",
      "  %onnx::Transpose_1240 = Reshape(%onnx::Reshape_1230, %onnx::Reshape_1688)\n",
      "  %onnx::Add_1242 = MatMul(%onnx::MatMul_1224, %onnx::MatMul_1689)\n",
      "  %onnx::Reshape_1243 = Add(%bert.encoder.layer.10.attention.self.value.bias, %onnx::Add_1242)\n",
      "  %onnx::Transpose_1253 = Reshape(%onnx::Reshape_1243, %onnx::Reshape_1694)\n",
      "  %onnx::MatMul_1254 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1253)\n",
      "  %onnx::Transpose_1264 = Reshape(%mixed_query_layer.39, %onnx::Reshape_1699)\n",
      "  %onnx::MatMul_1265 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1264)\n",
      "  %onnx::MatMul_1266 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1240)\n",
      "  %onnx::Div_1267 = MatMul(%onnx::MatMul_1265, %onnx::MatMul_1266)\n",
      "  %onnx::Div_1268 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1269 = Div(%onnx::Div_1267, %onnx::Div_1268)\n",
      "  %attention_scores.39 = Add(%onnx::Add_1269, %onnx::Add_227)\n",
      "  %input.212 = Softmax[axis = 3](%attention_scores.39)\n",
      "  %onnx::Transpose_1272 = MatMul(%input.212, %onnx::MatMul_1254)\n",
      "  %onnx::Reshape_1273 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1272)\n",
      "  %onnx::MatMul_1281 = Reshape(%onnx::Reshape_1273, %onnx::Reshape_1703)\n",
      "  %onnx::Add_1283 = MatMul(%onnx::MatMul_1281, %onnx::MatMul_1704)\n",
      "  %input.216 = Add(%bert.encoder.layer.10.attention.output.dense.bias, %onnx::Add_1283)\n",
      "  %input.220 = Add(%input.216, %onnx::MatMul_1224)\n",
      "  %onnx::Sub_1286 = ReduceMean[axes = [-1]](%input.220)\n",
      "  %onnx::Pow_1287 = Sub(%input.220, %onnx::Sub_1286)\n",
      "  %onnx::Pow_1288 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1289 = Pow(%onnx::Pow_1287, %onnx::Pow_1288)\n",
      "  %onnx::Add_1290 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1289)\n",
      "  %onnx::Add_1291 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1292 = Add(%onnx::Add_1290, %onnx::Add_1291)\n",
      "  %onnx::Div_1293 = Sqrt(%onnx::Sqrt_1292)\n",
      "  %onnx::Mul_1294 = Div(%onnx::Pow_1287, %onnx::Div_1293)\n",
      "  %onnx::Add_1295 = Mul(%onnx::Mul_1294, %bert.encoder.layer.10.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1296 = Add(%onnx::Add_1295, %bert.encoder.layer.10.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1298 = MatMul(%onnx::MatMul_1296, %onnx::MatMul_1705)\n",
      "  %onnx::Div_1299 = Add(%bert.encoder.layer.10.intermediate.dense.bias, %onnx::Add_1298)\n",
      "  %onnx::Div_1300 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1301 = Div(%onnx::Div_1299, %onnx::Div_1300)\n",
      "  %onnx::Add_1302 = Erf(%onnx::Erf_1301)\n",
      "  %onnx::Add_1303 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1304 = Add(%onnx::Add_1302, %onnx::Add_1303)\n",
      "  %onnx::Mul_1305 = Mul(%onnx::Div_1299, %onnx::Mul_1304)\n",
      "  %onnx::Mul_1306 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1307 = Mul(%onnx::Mul_1305, %onnx::Mul_1306)\n",
      "  %onnx::Add_1309 = MatMul(%onnx::MatMul_1307, %onnx::MatMul_1706)\n",
      "  %input.224 = Add(%bert.encoder.layer.10.output.dense.bias, %onnx::Add_1309)\n",
      "  %input.228 = Add(%input.224, %onnx::MatMul_1296)\n",
      "  %onnx::Sub_1312 = ReduceMean[axes = [-1]](%input.228)\n",
      "  %onnx::Pow_1313 = Sub(%input.228, %onnx::Sub_1312)\n",
      "  %onnx::Pow_1314 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1315 = Pow(%onnx::Pow_1313, %onnx::Pow_1314)\n",
      "  %onnx::Add_1316 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1315)\n",
      "  %onnx::Add_1317 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1318 = Add(%onnx::Add_1316, %onnx::Add_1317)\n",
      "  %onnx::Div_1319 = Sqrt(%onnx::Sqrt_1318)\n",
      "  %onnx::Mul_1320 = Div(%onnx::Pow_1313, %onnx::Div_1319)\n",
      "  %onnx::Add_1321 = Mul(%onnx::Mul_1320, %bert.encoder.layer.10.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1322 = Add(%onnx::Add_1321, %bert.encoder.layer.10.output.LayerNorm.bias)\n",
      "  %onnx::Add_1324 = MatMul(%onnx::MatMul_1322, %onnx::MatMul_1707)\n",
      "  %mixed_query_layer.43 = Add(%bert.encoder.layer.11.attention.self.query.bias, %onnx::Add_1324)\n",
      "  %onnx::Add_1327 = MatMul(%onnx::MatMul_1322, %onnx::MatMul_1708)\n",
      "  %onnx::Reshape_1328 = Add(%bert.encoder.layer.11.attention.self.key.bias, %onnx::Add_1327)\n",
      "  %onnx::Transpose_1338 = Reshape(%onnx::Reshape_1328, %onnx::Reshape_1713)\n",
      "  %onnx::Add_1340 = MatMul(%onnx::MatMul_1322, %onnx::MatMul_1714)\n",
      "  %onnx::Reshape_1341 = Add(%bert.encoder.layer.11.attention.self.value.bias, %onnx::Add_1340)\n",
      "  %onnx::Transpose_1351 = Reshape(%onnx::Reshape_1341, %onnx::Reshape_1719)\n",
      "  %onnx::MatMul_1352 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1351)\n",
      "  %onnx::Transpose_1362 = Reshape(%mixed_query_layer.43, %onnx::Reshape_1724)\n",
      "  %onnx::MatMul_1363 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1362)\n",
      "  %onnx::MatMul_1364 = Transpose[perm = [0, 2, 3, 1]](%onnx::Transpose_1338)\n",
      "  %onnx::Div_1365 = MatMul(%onnx::MatMul_1363, %onnx::MatMul_1364)\n",
      "  %onnx::Div_1366 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Add_1367 = Div(%onnx::Div_1365, %onnx::Div_1366)\n",
      "  %attention_scores.43 = Add(%onnx::Add_1367, %onnx::Add_227)\n",
      "  %input.232 = Softmax[axis = 3](%attention_scores.43)\n",
      "  %onnx::Transpose_1370 = MatMul(%input.232, %onnx::MatMul_1352)\n",
      "  %onnx::Reshape_1371 = Transpose[perm = [0, 2, 1, 3]](%onnx::Transpose_1370)\n",
      "  %onnx::MatMul_1379 = Reshape(%onnx::Reshape_1371, %onnx::Reshape_1728)\n",
      "  %onnx::Add_1381 = MatMul(%onnx::MatMul_1379, %onnx::MatMul_1729)\n",
      "  %input.236 = Add(%bert.encoder.layer.11.attention.output.dense.bias, %onnx::Add_1381)\n",
      "  %input.240 = Add(%input.236, %onnx::MatMul_1322)\n",
      "  %onnx::Sub_1384 = ReduceMean[axes = [-1]](%input.240)\n",
      "  %onnx::Pow_1385 = Sub(%input.240, %onnx::Sub_1384)\n",
      "  %onnx::Pow_1386 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1387 = Pow(%onnx::Pow_1385, %onnx::Pow_1386)\n",
      "  %onnx::Add_1388 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1387)\n",
      "  %onnx::Add_1389 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1390 = Add(%onnx::Add_1388, %onnx::Add_1389)\n",
      "  %onnx::Div_1391 = Sqrt(%onnx::Sqrt_1390)\n",
      "  %onnx::Mul_1392 = Div(%onnx::Pow_1385, %onnx::Div_1391)\n",
      "  %onnx::Add_1393 = Mul(%onnx::Mul_1392, %bert.encoder.layer.11.attention.output.LayerNorm.weight)\n",
      "  %onnx::MatMul_1394 = Add(%onnx::Add_1393, %bert.encoder.layer.11.attention.output.LayerNorm.bias)\n",
      "  %onnx::Add_1396 = MatMul(%onnx::MatMul_1394, %onnx::MatMul_1730)\n",
      "  %onnx::Div_1397 = Add(%bert.encoder.layer.11.intermediate.dense.bias, %onnx::Add_1396)\n",
      "  %onnx::Div_1398 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Erf_1399 = Div(%onnx::Div_1397, %onnx::Div_1398)\n",
      "  %onnx::Add_1400 = Erf(%onnx::Erf_1399)\n",
      "  %onnx::Add_1401 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Mul_1402 = Add(%onnx::Add_1400, %onnx::Add_1401)\n",
      "  %onnx::Mul_1403 = Mul(%onnx::Div_1397, %onnx::Mul_1402)\n",
      "  %onnx::Mul_1404 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::MatMul_1405 = Mul(%onnx::Mul_1403, %onnx::Mul_1404)\n",
      "  %onnx::Add_1407 = MatMul(%onnx::MatMul_1405, %onnx::MatMul_1731)\n",
      "  %input.244 = Add(%bert.encoder.layer.11.output.dense.bias, %onnx::Add_1407)\n",
      "  %input.248 = Add(%input.244, %onnx::MatMul_1394)\n",
      "  %onnx::Sub_1410 = ReduceMean[axes = [-1]](%input.248)\n",
      "  %onnx::Pow_1411 = Sub(%input.248, %onnx::Sub_1410)\n",
      "  %onnx::Pow_1412 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::ReduceMean_1413 = Pow(%onnx::Pow_1411, %onnx::Pow_1412)\n",
      "  %onnx::Add_1414 = ReduceMean[axes = [-1]](%onnx::ReduceMean_1413)\n",
      "  %onnx::Add_1415 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Sqrt_1416 = Add(%onnx::Add_1414, %onnx::Add_1415)\n",
      "  %onnx::Div_1417 = Sqrt(%onnx::Sqrt_1416)\n",
      "  %onnx::Mul_1418 = Div(%onnx::Pow_1411, %onnx::Div_1417)\n",
      "  %onnx::Add_1419 = Mul(%onnx::Mul_1418, %bert.encoder.layer.11.output.LayerNorm.weight)\n",
      "  %onnx::Gather_1420 = Add(%onnx::Add_1419, %bert.encoder.layer.11.output.LayerNorm.bias)\n",
      "  %onnx::Gather_1421 = Constant[value = <Scalar Tensor []>]()\n",
      "  %onnx::Gemm_1422 = Gather[axis = 1](%onnx::Gather_1420, %onnx::Gather_1421)\n",
      "  %input.252 = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_1422, %classifier.0.weight, %classifier.0.bias)\n",
      "  %onnx::Gemm_1424 = Relu(%input.252)\n",
      "  %output = Gemm[alpha = 1, beta = 1, transB = 1](%onnx::Gemm_1424, %classifier.2.weight, %classifier.2.bias)\n",
      "  return %output\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# check model:\n",
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"models/news_model.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:  tech\n"
     ]
    }
   ],
   "source": [
    "label, text = get_input_data(\"data/bbc-text_test.csv\", 445)\n",
    "print(\"label: \",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x)/sum(np.exp(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tech'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "ort_session = ort.InferenceSession(\"models/news_model.onnx\")\n",
    "inputs = preprocessing_for_bert([text])\n",
    "outputs = ort_session.run(\n",
    "    None,\n",
    "    {\"input_ids\": inputs[0].numpy(), \"input_masks\":inputs[1].numpy()},\n",
    ")\n",
    "# print(outputs)  # list with one element: Numpy array of the logits\n",
    "probs = softmax(outputs[0][0])\n",
    "pred = np.argmax(probs)\n",
    "le_news.inverse_transform([pred])[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
